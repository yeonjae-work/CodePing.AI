name: ðŸš€ CodePing.AI CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

env:
  PYTHON_VERSION: "3.12"
  POETRY_VERSION: "1.7.1"

jobs:
  # ðŸ” ì½”ë“œ í’ˆì§ˆ ë° ë³´ì•ˆ ê²€ì‚¬
  code-quality:
    name: ðŸ“Š Code Quality & Security
    runs-on: ubuntu-latest
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: ðŸ“¦ Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: ðŸ”§ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install flake8 black isort bandit safety mypy pytest-cov
        
    - name: ðŸŽ¨ Code formatting check (Black)
      run: |
        black --check --diff .
        
    - name: ðŸ“ Import sorting check (isort)
      run: |
        isort --check-only --diff .
        
    - name: ðŸ” Linting (Flake8)
      run: |
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
        
    - name: ðŸ›¡ï¸ Security check (Bandit)
      run: |
        bandit -r . -f json -o bandit-report.json || true
        bandit -r . --severity-level medium
        
    - name: ðŸ”’ Dependency vulnerability check (Safety)
      run: |
        safety check --json --output safety-report.json || true
        safety check
        
    - name: ðŸ·ï¸ Type checking (MyPy)
      run: |
        mypy . --ignore-missing-imports --no-strict-optional || true
        
    - name: ðŸ“Š Upload security reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json

  # ðŸ§ª ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ë° í†µí•© í…ŒìŠ¤íŠ¸
  test:
    name: ðŸ§ª Tests
    runs-on: ubuntu-latest
    needs: code-quality
    
    strategy:
      matrix:
        python-version: ["3.11", "3.12"]
        
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: testpassword
          POSTGRES_USER: testuser
          POSTGRES_DB: testdb
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
          
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        
    - name: ðŸ“¦ Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-${{ matrix.python-version }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-${{ matrix.python-version }}-pip-
          
    - name: ðŸ”§ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-asyncio pytest-mock
        
    - name: ðŸ”§ Set up test environment
      run: |
        cp .env.example .env.test
        echo "DATABASE_URL=postgresql://testuser:testpassword@localhost:5432/testdb" >> .env.test
        echo "TESTING=true" >> .env.test
        
    - name: ðŸ§ª Run unit tests
      env:
        DATABASE_URL: postgresql://testuser:testpassword@localhost:5432/testdb
        TESTING: true
      run: |
        pytest tests/ -v --cov=. --cov-report=xml --cov-report=html --cov-fail-under=70
        
    - name: ðŸ§ª Run integration tests
      env:
        DATABASE_URL: postgresql://testuser:testpassword@localhost:5432/testdb
        TESTING: true
      run: |
        python examples/simple_integration_test.py
        
    - name: ðŸ“Š Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

  # ðŸ³ Docker ë¹Œë“œ ë° í…ŒìŠ¤íŠ¸
  docker-build:
    name: ðŸ³ Docker Build & Test
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ³ Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      
    - name: ðŸ”§ Build Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./Dockerfile
        push: false
        tags: codeping-ai:test
        cache-from: type=gha
        cache-to: type=gha,mode=max
        
    - name: ðŸ§ª Test Docker image
      run: |
        docker run --rm codeping-ai:test python -c "
        import sys
        print(f'Python version: {sys.version}')
        
        # PyPI íŒ¨í‚¤ì§€ë“¤ import í…ŒìŠ¤íŠ¸
        try:
            from universal_data_storage.models import Event
            from universal_webhook_receiver.router import WebhookService
            print('âœ… PyPI packages import successful')
        except Exception as e:
            print(f'âŒ PyPI packages import failed: {e}')
            sys.exit(1)
            
        print('ðŸŽ‰ Docker image test passed!')
        "

  # ðŸ” ë³´ì•ˆ ìŠ¤ìº”
  security-scan:
    name: ðŸ” Security Scan
    runs-on: ubuntu-latest
    needs: code-quality
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ” Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
        
    - name: ðŸ“Š Upload Trivy scan results
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'

  # ðŸ“ˆ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
  performance-test:
    name: ðŸ“ˆ Performance Test
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: ðŸ”§ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install locust memory-profiler
        
    - name: ðŸ“ˆ Run performance tests
      run: |
        python -c "
        import time
        import psutil
        import gc
        from memory_profiler import profile
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸
        def test_memory_usage():
            start_memory = psutil.Process().memory_info().rss / 1024 / 1024
            
            # PyPI íŒ¨í‚¤ì§€ë“¤ import
            from universal_data_storage.models import Event
            from universal_webhook_receiver.router import WebhookService
            from universal_git_data_parser.service import GitDataParserService
            
            # ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            services = []
            for i in range(100):
                services.append(GitDataParserService())
            
            end_memory = psutil.Process().memory_info().rss / 1024 / 1024
            memory_diff = end_memory - start_memory
            
            print(f'Memory usage: {start_memory:.2f}MB -> {end_memory:.2f}MB (diff: {memory_diff:.2f}MB)')
            
            if memory_diff > 500:  # 500MB ì´ìƒ ì¦ê°€ì‹œ ê²½ê³ 
                print('âš ï¸ High memory usage detected')
            else:
                print('âœ… Memory usage within acceptable range')
                
            del services
            gc.collect()
            
        test_memory_usage()
        "

  # ðŸš€ ë°°í¬ ì¤€ë¹„
  deployment-ready:
    name: ðŸš€ Deployment Ready
    runs-on: ubuntu-latest
    needs: [code-quality, test, docker-build]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ·ï¸ Generate deployment info
      run: |
        echo "ðŸŽ‰ All checks passed! Ready for deployment."
        echo "ðŸ“Š Deployment Summary:"
        echo "- Commit SHA: ${{ github.sha }}"
        echo "- Branch: ${{ github.ref_name }}"
        echo "- Author: ${{ github.actor }}"
        echo "- Timestamp: $(date -u +"%Y-%m-%d %H:%M:%S UTC")"
        echo "- PyPI Packages: 12/12 integrated"
        echo "- Tests: Passed"
        echo "- Security: Scanned"
        echo "- Docker: Built & Tested"
        
    - name: ðŸ“ Create deployment artifact
      run: |
        mkdir -p deployment-info
        cat > deployment-info/deployment.json << EOF
        {
          "commit_sha": "${{ github.sha }}",
          "branch": "${{ github.ref_name }}",
          "author": "${{ github.actor }}",
          "timestamp": "$(date -u +"%Y-%m-%d %H:%M:%S UTC")",
          "pypi_packages": 12,
          "tests_passed": true,
          "security_scanned": true,
          "docker_ready": true,
          "deployment_ready": true
        }
        EOF
        
    - name: ðŸ“Š Upload deployment info
      uses: actions/upload-artifact@v3
      with:
        name: deployment-info
        path: deployment-info/

  # ðŸ“± ì•Œë¦¼
  notification:
    name: ðŸ“± Notification
    runs-on: ubuntu-latest
    needs: [deployment-ready]
    if: always()
    
    steps:
    - name: ðŸ“± Send success notification
      if: needs.deployment-ready.result == 'success'
      run: |
        echo "âœ… CI Pipeline completed successfully!"
        echo "ðŸš€ CodePing.AI is ready for deployment"
        
    - name: ðŸ“± Send failure notification  
      if: failure()
      run: |
        echo "âŒ CI Pipeline failed!"
        echo "ðŸ”§ Please check the logs and fix the issues" 